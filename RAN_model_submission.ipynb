{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzLzbxFmauhv"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow.keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import Add\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Multiply\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import UpSampling2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p89GsXpXFuEF",
        "outputId": "d8558515-68e8-4b17-ed35-53960d485923"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXaUyZv8GiVo"
      },
      "source": [
        "num_classes = 10\n",
        "\n",
        "x_train = x_train.astype('float16')\n",
        "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
        "\n",
        "x_test = x_test.astype('float16')\n",
        "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "mean_image = np.mean(x_train, axis=0)\n",
        "x_train -= mean_image\n",
        "x_test -= mean_image"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj1GPrlQHcU-"
      },
      "source": [
        "def conv_unit(x, filters, kernel_size, weight_decay=0.0, strides=(1,1)):\n",
        "    layer = Conv2D(filters, kernel_size, strides, padding='same',\n",
        "                   use_bias=False, kernel_regularizer=l2(weight_decay)\n",
        "                  )(x)\n",
        "    layer = BatchNormalization()(layer)\n",
        "    return layer\n",
        "\n",
        "def residual_unit(x, filters, kernel_size, weight_decay, downsample=True):\n",
        "    if downsample:\n",
        "        residual_x = conv_unit(x, filters, kernel_size=1, strides=1)\n",
        "        stride = 1\n",
        "    else:\n",
        "        residual_x = x\n",
        "        stride = 1\n",
        "    out = conv_unit(x, filters, kernel_size, weight_decay, stride)\n",
        "    residual = Activation('relu')(out)\n",
        "    out = Add()([residual_x, residual])\n",
        "    out = Activation('relu')(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "def attention_module(attention_input, p, t, r, filters, weight_decay):\n",
        "    \n",
        "    # residual unit * p\n",
        "    res_out_1 = attention_input\n",
        "    for i in range(p):\n",
        "        res_out_1 = residual_unit(res_out_1, filters, (3, 3), weight_decay, downsample=True)\n",
        "    \n",
        "    \n",
        "    #=============================================================================\n",
        "    # Trunk Branch: residual unit * t\n",
        "    #============================================================================= \n",
        "    trunk_out = res_out_1\n",
        "    for i in range(t):\n",
        "        trunk_out = residual_unit(trunk_out, filters, (3, 3), weight_decay, downsample=True)\n",
        "    \n",
        "    \n",
        "    #=============================================================================\n",
        "    #Soft Mask Branch:\n",
        "    #=============================================================================\n",
        "    # Downsampling: Maxpooling\n",
        "    down_out_1 = MaxPool2D(pool_size=(2, 2),\n",
        "                          padding='same')(res_out_1)\n",
        "    \n",
        "    # residual unit * r\n",
        "    res_out_2 = down_out_1\n",
        "    for i in range(r):\n",
        "        res_out_2 = residual_unit(res_out_2, filters, (3, 3), weight_decay, downsample=True)\n",
        "\n",
        "    # Downsampling: Maxpooling\n",
        "    down_out_2 = MaxPool2D(pool_size=(2, 2),\n",
        "                          padding='same')(res_out_2)\n",
        "    # residual unit * 2r\n",
        "    res_out_3 = down_out_2\n",
        "    for i in range(2*r):\n",
        "        res_out_3 = residual_unit(res_out_3, filters, (3, 3), weight_decay, downsample=True)\n",
        "\n",
        "    # Upsampling: interpolation\n",
        "    up_out_1 = UpSampling2D(size=(2, 2))(res_out_3)\n",
        "    \n",
        "    # shortcut\n",
        "    shortcut_out = residual_unit(res_out_2, filters, (3, 3), weight_decay, downsample=True)\n",
        "    combine_out_1 = Add()([shortcut_out, up_out_1])\n",
        "    \n",
        "    \n",
        "    # residual unit * r\n",
        "    res_out_4 = up_out_1\n",
        "    for i in range(r):\n",
        "        res_out_4 = residual_unit(combine_out_1, filters, (3, 3), weight_decay, downsample=True)\n",
        "\n",
        "\n",
        "    # Upsampling: interpolation\n",
        "    up_out_2 = UpSampling2D(size=(2, 2))(res_out_4)\n",
        "    \n",
        "    # Conv * 2\n",
        "    f = up_out_2.shape[-1]\n",
        "    conv_out_1 = Conv2D(filters=f,\n",
        "                         kernel_size=(1,1),\n",
        "                         padding='same')(up_out_2)\n",
        "    bn_out = BatchNormalization()(conv_out_1)\n",
        "        \n",
        "    conv_out_2 = Conv2D(filters=f,\n",
        "                   kernel_size=(1,1),\n",
        "                   padding='same')(bn_out)\n",
        "    \n",
        "    # Activation: sigmoid\n",
        "    mask_out = Activation('sigmoid')(conv_out_2)\n",
        "    \n",
        "    \n",
        "    #=============================================================================\n",
        "    # Element-wise product and sum of soft mask branch and trunk branch\n",
        "    #=============================================================================\n",
        "    # (1+M(x))*T(x)\n",
        "    combine_out_2 = Multiply()([Lambda(lambda x: 1 + x)(mask_out), trunk_out])\n",
        "    \n",
        "    # residual unit * p\n",
        "    res_out_5 = combine_out_2\n",
        "    for i in range(p):\n",
        "        res_out_5 = residual_unit(res_out_5, filters, (3, 3), weight_decay, downsample=True)\n",
        "    \n",
        "    attention_input = res_out_5\n",
        "    \n",
        "    return attention_input"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a90UH0c6HeT1"
      },
      "source": [
        "input_data = Input(shape=(32, 32, 3))\n",
        "\n",
        "# Conv1\n",
        "conv_out_1 = Conv2D(filters=32,\n",
        "                      kernel_size=(3,3),\n",
        "                      padding='same')(input_data)\n",
        "# Max pooling        \n",
        "maxpool_out_1 = MaxPool2D(pool_size=(2, 2),\n",
        "                          padding='same')(conv_out_1)\n",
        "\n",
        "# Redisual unit + Attention Module\n",
        "residual_out_1 = residual_unit(maxpool_out_1, 32, (3, 3), 1e-4)\n",
        "attention_out_1 = attention_module(residual_out_1, 1, 2, 1, 32, 1e-4)\n",
        "residual_out_2 = residual_unit(attention_out_1, 64, (3, 3), 1e-4)\n",
        "attention_out_2 = attention_module(residual_out_2,  1, 2, 1, 64, 1e-4)\n",
        "residual_out_3 = residual_unit(attention_out_2, 128, (3, 3), 1e-4)\n",
        "attention_out_3 = attention_module(residual_out_3,  1, 2, 1, 128, 1e-4)\n",
        "residual_out_4 = residual_unit(attention_out_3, 256, (3, 3), 1e-4)\n",
        "residual_out_5 = residual_unit(residual_out_4, 256, (3, 3), 1e-4)\n",
        "residual_out_6 = residual_unit(residual_out_5, 256, (3, 3), 1e-4)\n",
        "\n",
        "# Avg Pooling\n",
        "avgpool_out = AveragePooling2D(pool_size=(2, 2), strides=(2, 2))(residual_out_6)\n",
        "\n",
        "# Flatten the data\n",
        "flatten_out = Flatten()(avgpool_out)\n",
        "\n",
        "# FC Layers for prediction\n",
        "fc_out = Dense(512, activation='relu')(flatten_out)\n",
        "fully_connected_layer_last = Dense(10,activation=\"softmax\")(fc_out)\n",
        "         \n",
        "# Fully constructed model\n",
        "model = Model(inputs=input_data, outputs=fully_connected_layer_last)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZScu-7TwHiZK",
        "outputId": "c8f51cb6-842b-4a19-8ec1-c5f391e9cb9b"
      },
      "source": [
        "# get data\n",
        "num_train = int(x_train.shape[0] * 0.8)\n",
        "num_val = x_train.shape[0] - num_train\n",
        "mask = list(range(num_train, num_train+num_val))\n",
        "x_val = x_train[mask]\n",
        "y_val = y_train[mask]\n",
        "\n",
        "mask = list(range(num_train))\n",
        "x_train = x_train[mask]\n",
        "y_train = y_train[mask]\n",
        "\n",
        "data = (x_train, y_train, x_val, y_val, x_test, y_test)\n",
        "print(\"Training data shape: \", x_train.shape)\n",
        "print(\"Training label shape: \", y_train.shape)\n",
        "print(\"Test data shape: \", x_test.shape)\n",
        "print(\"Test label shape: \", y_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape:  (40000, 32, 32, 3)\n",
            "Training label shape:  (40000, 10)\n",
            "Test data shape:  (10000, 32, 32, 3)\n",
            "Test label shape:  (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-JgHbACHkrE"
      },
      "source": [
        "model.compile(optimizer=optimizers.SGD(lr=1e-1, \n",
        "                                       momentum=0.9, \n",
        "                                       nesterov=False),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxfb83keHmkt",
        "outputId": "476c8c52-dda6-4cf3-8175-78695291b489"
      },
      "source": [
        "def lr_scheduler(epoch):\n",
        "    new_lr = 1e-1 * (0.1 ** (epoch // 75))\n",
        "    print('new lr:%.2e' % new_lr)\n",
        "    return new_lr \n",
        "\n",
        "reduce_lr = LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "datagen = ImageDataGenerator( \n",
        "    width_shift_range=0.125,  \n",
        "    height_shift_range=0.125,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "train_gen = datagen.flow(x_train, y_train, batch_size=64)\n",
        "history = model.fit_generator(generator=train_gen,\n",
        "                              epochs=200,\n",
        "                              callbacks=[reduce_lr],\n",
        "                              validation_data=(x_val, y_val))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 66s 86ms/step - loss: 15.9913 - accuracy: 0.1007 - val_loss: 12.9816 - val_accuracy: 0.1037\n",
            "Epoch 2/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 53s 85ms/step - loss: 12.3466 - accuracy: 0.1074 - val_loss: 10.6075 - val_accuracy: 0.1143\n",
            "Epoch 3/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 10.1173 - accuracy: 0.1116 - val_loss: 8.6968 - val_accuracy: 0.1610\n",
            "Epoch 4/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 8.2285 - accuracy: 0.2068 - val_loss: 7.2900 - val_accuracy: 0.1733\n",
            "Epoch 5/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 6.7032 - accuracy: 0.2641 - val_loss: 6.3266 - val_accuracy: 0.1984\n",
            "Epoch 6/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 5.5926 - accuracy: 0.2918 - val_loss: 4.8772 - val_accuracy: 0.3306\n",
            "Epoch 7/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 4.7356 - accuracy: 0.3081 - val_loss: 4.0894 - val_accuracy: 0.3830\n",
            "Epoch 8/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 55s 87ms/step - loss: 4.0184 - accuracy: 0.3484 - val_loss: 3.5193 - val_accuracy: 0.3903\n",
            "Epoch 9/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 3.4994 - accuracy: 0.3558 - val_loss: 3.1024 - val_accuracy: 0.3984\n",
            "Epoch 10/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 3.0811 - accuracy: 0.3732 - val_loss: 2.7494 - val_accuracy: 0.4122\n",
            "Epoch 11/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 2.7532 - accuracy: 0.3864 - val_loss: 2.5657 - val_accuracy: 0.3957\n",
            "Epoch 12/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 2.4947 - accuracy: 0.3963 - val_loss: 2.4004 - val_accuracy: 0.3951\n",
            "Epoch 13/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 2.2832 - accuracy: 0.4076 - val_loss: 2.0853 - val_accuracy: 0.4544\n",
            "Epoch 14/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 2.1226 - accuracy: 0.4138 - val_loss: 2.0185 - val_accuracy: 0.4309\n",
            "Epoch 15/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.9775 - accuracy: 0.4333 - val_loss: 1.8948 - val_accuracy: 0.4344\n",
            "Epoch 16/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.8723 - accuracy: 0.4453 - val_loss: 1.9828 - val_accuracy: 0.3948\n",
            "Epoch 17/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.7505 - accuracy: 0.4718 - val_loss: 1.7893 - val_accuracy: 0.4430\n",
            "Epoch 18/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.6428 - accuracy: 0.4960 - val_loss: 1.6985 - val_accuracy: 0.4934\n",
            "Epoch 19/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.5565 - accuracy: 0.5180 - val_loss: 2.0912 - val_accuracy: 0.3937\n",
            "Epoch 20/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.4710 - accuracy: 0.5490 - val_loss: 1.3334 - val_accuracy: 0.5960\n",
            "Epoch 21/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.3857 - accuracy: 0.5777 - val_loss: 1.5048 - val_accuracy: 0.5377\n",
            "Epoch 22/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.3209 - accuracy: 0.5974 - val_loss: 1.4324 - val_accuracy: 0.5590\n",
            "Epoch 23/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.2839 - accuracy: 0.6097 - val_loss: 1.3398 - val_accuracy: 0.6034\n",
            "Epoch 24/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.2543 - accuracy: 0.6241 - val_loss: 1.2666 - val_accuracy: 0.6382\n",
            "Epoch 25/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.2220 - accuracy: 0.6370 - val_loss: 1.2773 - val_accuracy: 0.6176\n",
            "Epoch 26/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.1932 - accuracy: 0.6452 - val_loss: 1.3664 - val_accuracy: 0.5867\n",
            "Epoch 27/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.1619 - accuracy: 0.6627 - val_loss: 1.1675 - val_accuracy: 0.6560\n",
            "Epoch 28/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.1484 - accuracy: 0.6679 - val_loss: 1.3157 - val_accuracy: 0.6359\n",
            "Epoch 29/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.1531 - accuracy: 0.6692 - val_loss: 1.1581 - val_accuracy: 0.6777\n",
            "Epoch 30/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.1145 - accuracy: 0.6867 - val_loss: 1.2850 - val_accuracy: 0.6299\n",
            "Epoch 31/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.1105 - accuracy: 0.6921 - val_loss: 1.5142 - val_accuracy: 0.5769\n",
            "Epoch 32/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.0941 - accuracy: 0.6976 - val_loss: 1.1887 - val_accuracy: 0.6698\n",
            "Epoch 33/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.0813 - accuracy: 0.7031 - val_loss: 1.4713 - val_accuracy: 0.6180\n",
            "Epoch 34/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.0853 - accuracy: 0.7066 - val_loss: 1.1823 - val_accuracy: 0.6824\n",
            "Epoch 35/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.0723 - accuracy: 0.7121 - val_loss: 1.1792 - val_accuracy: 0.6845\n",
            "Epoch 36/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.0640 - accuracy: 0.7163 - val_loss: 1.2027 - val_accuracy: 0.6916\n",
            "Epoch 37/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.0846 - accuracy: 0.7177 - val_loss: 1.1281 - val_accuracy: 0.7093\n",
            "Epoch 38/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.0520 - accuracy: 0.7274 - val_loss: 1.3001 - val_accuracy: 0.6562\n",
            "Epoch 39/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.0401 - accuracy: 0.7358 - val_loss: 1.3445 - val_accuracy: 0.6531\n",
            "Epoch 40/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.0359 - accuracy: 0.7374 - val_loss: 1.1643 - val_accuracy: 0.7036\n",
            "Epoch 41/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.0237 - accuracy: 0.7423 - val_loss: 1.2318 - val_accuracy: 0.6947\n",
            "Epoch 42/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.0285 - accuracy: 0.7394 - val_loss: 1.4002 - val_accuracy: 0.6411\n",
            "Epoch 43/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.0298 - accuracy: 0.7422 - val_loss: 1.3272 - val_accuracy: 0.6699\n",
            "Epoch 44/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.0092 - accuracy: 0.7514 - val_loss: 1.1780 - val_accuracy: 0.6878\n",
            "Epoch 45/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9951 - accuracy: 0.7535 - val_loss: 1.3190 - val_accuracy: 0.6660\n",
            "Epoch 46/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.0028 - accuracy: 0.7511 - val_loss: 1.3763 - val_accuracy: 0.6707\n",
            "Epoch 47/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.0121 - accuracy: 0.7565 - val_loss: 1.2343 - val_accuracy: 0.6851\n",
            "Epoch 48/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.0065 - accuracy: 0.7576 - val_loss: 1.3120 - val_accuracy: 0.6822\n",
            "Epoch 49/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 1.0077 - accuracy: 0.7561 - val_loss: 1.2184 - val_accuracy: 0.7157\n",
            "Epoch 50/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 0.9946 - accuracy: 0.7658 - val_loss: 1.1912 - val_accuracy: 0.6851\n",
            "Epoch 51/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9848 - accuracy: 0.7650 - val_loss: 1.0392 - val_accuracy: 0.7607\n",
            "Epoch 52/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9789 - accuracy: 0.7726 - val_loss: 1.0921 - val_accuracy: 0.7304\n",
            "Epoch 53/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9615 - accuracy: 0.7732 - val_loss: 1.2198 - val_accuracy: 0.7056\n",
            "Epoch 54/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9486 - accuracy: 0.7833 - val_loss: 1.2623 - val_accuracy: 0.6936\n",
            "Epoch 55/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9572 - accuracy: 0.7785 - val_loss: 1.0821 - val_accuracy: 0.7441\n",
            "Epoch 56/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9658 - accuracy: 0.7778 - val_loss: 1.0690 - val_accuracy: 0.7534\n",
            "Epoch 57/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9399 - accuracy: 0.7889 - val_loss: 1.1064 - val_accuracy: 0.7366\n",
            "Epoch 58/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9330 - accuracy: 0.7893 - val_loss: 1.2805 - val_accuracy: 0.6976\n",
            "Epoch 59/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9340 - accuracy: 0.7898 - val_loss: 1.3389 - val_accuracy: 0.7004\n",
            "Epoch 60/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 0.9338 - accuracy: 0.7932 - val_loss: 1.4535 - val_accuracy: 0.6529\n",
            "Epoch 61/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 0.9391 - accuracy: 0.7894 - val_loss: 1.2336 - val_accuracy: 0.7083\n",
            "Epoch 62/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9396 - accuracy: 0.7954 - val_loss: 1.2844 - val_accuracy: 0.7078\n",
            "Epoch 63/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9432 - accuracy: 0.7945 - val_loss: 1.0252 - val_accuracy: 0.7625\n",
            "Epoch 64/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9123 - accuracy: 0.8015 - val_loss: 1.0208 - val_accuracy: 0.7699\n",
            "Epoch 65/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9124 - accuracy: 0.8029 - val_loss: 1.2838 - val_accuracy: 0.7319\n",
            "Epoch 66/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9048 - accuracy: 0.8068 - val_loss: 1.0051 - val_accuracy: 0.7737\n",
            "Epoch 67/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9670 - accuracy: 0.7897 - val_loss: 1.1028 - val_accuracy: 0.7555\n",
            "Epoch 68/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9418 - accuracy: 0.8014 - val_loss: 1.0467 - val_accuracy: 0.7689\n",
            "Epoch 69/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9280 - accuracy: 0.8059 - val_loss: 1.0004 - val_accuracy: 0.7810\n",
            "Epoch 70/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 0.9100 - accuracy: 0.8095 - val_loss: 1.0497 - val_accuracy: 0.7742\n",
            "Epoch 71/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.8969 - accuracy: 0.8144 - val_loss: 1.0888 - val_accuracy: 0.7700\n",
            "Epoch 72/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.8926 - accuracy: 0.8138 - val_loss: 1.1307 - val_accuracy: 0.7478\n",
            "Epoch 73/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9084 - accuracy: 0.8120 - val_loss: 1.1068 - val_accuracy: 0.7595\n",
            "Epoch 74/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9006 - accuracy: 0.8133 - val_loss: 1.0430 - val_accuracy: 0.7742\n",
            "Epoch 75/200\n",
            "new lr:1.00e-01\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.8875 - accuracy: 0.8179 - val_loss: 1.1133 - val_accuracy: 0.7539\n",
            "Epoch 76/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 0.8277 - accuracy: 0.8352 - val_loss: 0.8522 - val_accuracy: 0.8403\n",
            "Epoch 77/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 0.7275 - accuracy: 0.8672 - val_loss: 0.8357 - val_accuracy: 0.8451\n",
            "Epoch 78/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.7066 - accuracy: 0.8705 - val_loss: 0.8090 - val_accuracy: 0.8469\n",
            "Epoch 79/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.6680 - accuracy: 0.8808 - val_loss: 0.8037 - val_accuracy: 0.8529\n",
            "Epoch 80/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.6532 - accuracy: 0.8825 - val_loss: 0.8050 - val_accuracy: 0.8501\n",
            "Epoch 81/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.6345 - accuracy: 0.8877 - val_loss: 0.8001 - val_accuracy: 0.8496\n",
            "Epoch 82/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.6218 - accuracy: 0.8913 - val_loss: 0.7836 - val_accuracy: 0.8542\n",
            "Epoch 83/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 0.6051 - accuracy: 0.8920 - val_loss: 0.7742 - val_accuracy: 0.8553\n",
            "Epoch 84/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.5834 - accuracy: 0.8990 - val_loss: 0.7700 - val_accuracy: 0.8546\n",
            "Epoch 85/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.5817 - accuracy: 0.8960 - val_loss: 0.7591 - val_accuracy: 0.8559\n",
            "Epoch 86/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 0.5654 - accuracy: 0.8969 - val_loss: 0.7520 - val_accuracy: 0.8524\n",
            "Epoch 87/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.5541 - accuracy: 0.9020 - val_loss: 0.7482 - val_accuracy: 0.8597\n",
            "Epoch 88/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.5392 - accuracy: 0.9063 - val_loss: 0.7480 - val_accuracy: 0.8544\n",
            "Epoch 89/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.5306 - accuracy: 0.9058 - val_loss: 0.7309 - val_accuracy: 0.8571\n",
            "Epoch 90/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.5176 - accuracy: 0.9101 - val_loss: 0.7643 - val_accuracy: 0.8548\n",
            "Epoch 91/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 0.5074 - accuracy: 0.9097 - val_loss: 0.7657 - val_accuracy: 0.8534\n",
            "Epoch 92/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 0.5054 - accuracy: 0.9091 - val_loss: 0.7500 - val_accuracy: 0.8528\n",
            "Epoch 93/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 0.4928 - accuracy: 0.9116 - val_loss: 0.7724 - val_accuracy: 0.8586\n",
            "Epoch 94/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.4805 - accuracy: 0.9154 - val_loss: 0.7273 - val_accuracy: 0.8561\n",
            "Epoch 95/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.4783 - accuracy: 0.9140 - val_loss: 0.7196 - val_accuracy: 0.8516\n",
            "Epoch 96/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.4622 - accuracy: 0.9188 - val_loss: 0.7424 - val_accuracy: 0.8507\n",
            "Epoch 97/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.4520 - accuracy: 0.9203 - val_loss: 0.7175 - val_accuracy: 0.8551\n",
            "Epoch 98/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.4458 - accuracy: 0.9209 - val_loss: 0.6999 - val_accuracy: 0.8552\n",
            "Epoch 99/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.4465 - accuracy: 0.9208 - val_loss: 0.6981 - val_accuracy: 0.8583\n",
            "Epoch 100/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.4408 - accuracy: 0.9195 - val_loss: 0.7023 - val_accuracy: 0.8598\n",
            "Epoch 101/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.4251 - accuracy: 0.9246 - val_loss: 0.6976 - val_accuracy: 0.8611\n",
            "Epoch 102/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.4230 - accuracy: 0.9253 - val_loss: 0.7076 - val_accuracy: 0.8552\n",
            "Epoch 103/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.4124 - accuracy: 0.9289 - val_loss: 0.7196 - val_accuracy: 0.8561\n",
            "Epoch 104/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.4109 - accuracy: 0.9274 - val_loss: 0.7554 - val_accuracy: 0.8481\n",
            "Epoch 105/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.4103 - accuracy: 0.9263 - val_loss: 0.7422 - val_accuracy: 0.8547\n",
            "Epoch 106/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3992 - accuracy: 0.9314 - val_loss: 0.7522 - val_accuracy: 0.8504\n",
            "Epoch 107/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3981 - accuracy: 0.9296 - val_loss: 0.7487 - val_accuracy: 0.8559\n",
            "Epoch 108/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3896 - accuracy: 0.9308 - val_loss: 0.7037 - val_accuracy: 0.8552\n",
            "Epoch 109/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3925 - accuracy: 0.9289 - val_loss: 0.7437 - val_accuracy: 0.8548\n",
            "Epoch 110/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3854 - accuracy: 0.9322 - val_loss: 0.7565 - val_accuracy: 0.8524\n",
            "Epoch 111/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3795 - accuracy: 0.9336 - val_loss: 0.7247 - val_accuracy: 0.8510\n",
            "Epoch 112/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3776 - accuracy: 0.9323 - val_loss: 0.7729 - val_accuracy: 0.8527\n",
            "Epoch 113/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3722 - accuracy: 0.9345 - val_loss: 0.7637 - val_accuracy: 0.8499\n",
            "Epoch 114/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3692 - accuracy: 0.9342 - val_loss: 0.7540 - val_accuracy: 0.8456\n",
            "Epoch 115/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3677 - accuracy: 0.9362 - val_loss: 0.7105 - val_accuracy: 0.8556\n",
            "Epoch 116/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3637 - accuracy: 0.9347 - val_loss: 0.7331 - val_accuracy: 0.8543\n",
            "Epoch 117/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3611 - accuracy: 0.9359 - val_loss: 0.7323 - val_accuracy: 0.8549\n",
            "Epoch 118/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3575 - accuracy: 0.9375 - val_loss: 0.7163 - val_accuracy: 0.8490\n",
            "Epoch 119/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3518 - accuracy: 0.9377 - val_loss: 0.7961 - val_accuracy: 0.8509\n",
            "Epoch 120/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3492 - accuracy: 0.9395 - val_loss: 0.7329 - val_accuracy: 0.8527\n",
            "Epoch 121/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3517 - accuracy: 0.9395 - val_loss: 0.7500 - val_accuracy: 0.8510\n",
            "Epoch 122/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3487 - accuracy: 0.9380 - val_loss: 0.7230 - val_accuracy: 0.8537\n",
            "Epoch 123/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3521 - accuracy: 0.9370 - val_loss: 0.7551 - val_accuracy: 0.8494\n",
            "Epoch 124/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3467 - accuracy: 0.9399 - val_loss: 0.7739 - val_accuracy: 0.8520\n",
            "Epoch 125/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3416 - accuracy: 0.9408 - val_loss: 0.6908 - val_accuracy: 0.8556\n",
            "Epoch 126/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3419 - accuracy: 0.9386 - val_loss: 0.7737 - val_accuracy: 0.8522\n",
            "Epoch 127/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3379 - accuracy: 0.9426 - val_loss: 0.7386 - val_accuracy: 0.8509\n",
            "Epoch 128/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3366 - accuracy: 0.9412 - val_loss: 0.8164 - val_accuracy: 0.8512\n",
            "Epoch 129/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3353 - accuracy: 0.9419 - val_loss: 0.7835 - val_accuracy: 0.8538\n",
            "Epoch 130/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3378 - accuracy: 0.9405 - val_loss: 0.8795 - val_accuracy: 0.8344\n",
            "Epoch 131/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3357 - accuracy: 0.9417 - val_loss: 0.7909 - val_accuracy: 0.8438\n",
            "Epoch 132/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3307 - accuracy: 0.9421 - val_loss: 0.7866 - val_accuracy: 0.8472\n",
            "Epoch 133/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3309 - accuracy: 0.9450 - val_loss: 0.8837 - val_accuracy: 0.8515\n",
            "Epoch 134/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3346 - accuracy: 0.9422 - val_loss: 0.7917 - val_accuracy: 0.8567\n",
            "Epoch 135/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3286 - accuracy: 0.9438 - val_loss: 0.7596 - val_accuracy: 0.8515\n",
            "Epoch 136/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3242 - accuracy: 0.9454 - val_loss: 0.7933 - val_accuracy: 0.8529\n",
            "Epoch 137/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3231 - accuracy: 0.9441 - val_loss: 0.9134 - val_accuracy: 0.8531\n",
            "Epoch 138/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3240 - accuracy: 0.9454 - val_loss: 0.8019 - val_accuracy: 0.8461\n",
            "Epoch 139/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3214 - accuracy: 0.9453 - val_loss: 0.8305 - val_accuracy: 0.8545\n",
            "Epoch 140/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3154 - accuracy: 0.9465 - val_loss: 0.8629 - val_accuracy: 0.8517\n",
            "Epoch 141/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3261 - accuracy: 0.9451 - val_loss: 0.8877 - val_accuracy: 0.8515\n",
            "Epoch 142/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3224 - accuracy: 0.9457 - val_loss: 0.8770 - val_accuracy: 0.8431\n",
            "Epoch 143/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3219 - accuracy: 0.9451 - val_loss: 0.7849 - val_accuracy: 0.8602\n",
            "Epoch 144/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3261 - accuracy: 0.9430 - val_loss: 0.7716 - val_accuracy: 0.8529\n",
            "Epoch 145/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3128 - accuracy: 0.9491 - val_loss: 0.8137 - val_accuracy: 0.8500\n",
            "Epoch 146/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3197 - accuracy: 0.9469 - val_loss: 0.7491 - val_accuracy: 0.8503\n",
            "Epoch 147/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3174 - accuracy: 0.9467 - val_loss: 0.8229 - val_accuracy: 0.8458\n",
            "Epoch 148/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3153 - accuracy: 0.9482 - val_loss: 0.8197 - val_accuracy: 0.8468\n",
            "Epoch 149/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3189 - accuracy: 0.9466 - val_loss: 0.7801 - val_accuracy: 0.8511\n",
            "Epoch 150/200\n",
            "new lr:1.00e-02\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3189 - accuracy: 0.9462 - val_loss: 0.7524 - val_accuracy: 0.8551\n",
            "Epoch 151/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.3025 - accuracy: 0.9531 - val_loss: 0.7210 - val_accuracy: 0.8690\n",
            "Epoch 152/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2789 - accuracy: 0.9610 - val_loss: 0.7201 - val_accuracy: 0.8674\n",
            "Epoch 153/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2671 - accuracy: 0.9655 - val_loss: 0.7104 - val_accuracy: 0.8696\n",
            "Epoch 154/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2601 - accuracy: 0.9669 - val_loss: 0.7220 - val_accuracy: 0.8689\n",
            "Epoch 155/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2562 - accuracy: 0.9692 - val_loss: 0.7383 - val_accuracy: 0.8707\n",
            "Epoch 156/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2554 - accuracy: 0.9696 - val_loss: 0.7404 - val_accuracy: 0.8719\n",
            "Epoch 157/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2525 - accuracy: 0.9702 - val_loss: 0.7501 - val_accuracy: 0.8707\n",
            "Epoch 158/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2511 - accuracy: 0.9714 - val_loss: 0.7273 - val_accuracy: 0.8715\n",
            "Epoch 159/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2462 - accuracy: 0.9723 - val_loss: 0.7472 - val_accuracy: 0.8737\n",
            "Epoch 160/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2426 - accuracy: 0.9721 - val_loss: 0.7437 - val_accuracy: 0.8715\n",
            "Epoch 161/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2429 - accuracy: 0.9723 - val_loss: 0.7687 - val_accuracy: 0.8720\n",
            "Epoch 162/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2333 - accuracy: 0.9773 - val_loss: 0.7466 - val_accuracy: 0.8760\n",
            "Epoch 163/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2369 - accuracy: 0.9735 - val_loss: 0.7689 - val_accuracy: 0.8718\n",
            "Epoch 164/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2326 - accuracy: 0.9762 - val_loss: 0.7830 - val_accuracy: 0.8708\n",
            "Epoch 165/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2377 - accuracy: 0.9748 - val_loss: 0.7426 - val_accuracy: 0.8752\n",
            "Epoch 166/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2264 - accuracy: 0.9773 - val_loss: 0.7816 - val_accuracy: 0.8715\n",
            "Epoch 167/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2288 - accuracy: 0.9779 - val_loss: 0.7745 - val_accuracy: 0.8730\n",
            "Epoch 168/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2311 - accuracy: 0.9764 - val_loss: 0.7814 - val_accuracy: 0.8737\n",
            "Epoch 169/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 0.2277 - accuracy: 0.9764 - val_loss: 0.7854 - val_accuracy: 0.8719\n",
            "Epoch 170/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2282 - accuracy: 0.9774 - val_loss: 0.7844 - val_accuracy: 0.8720\n",
            "Epoch 171/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2234 - accuracy: 0.9782 - val_loss: 0.7915 - val_accuracy: 0.8730\n",
            "Epoch 172/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2212 - accuracy: 0.9784 - val_loss: 0.7801 - val_accuracy: 0.8722\n",
            "Epoch 173/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2233 - accuracy: 0.9784 - val_loss: 0.8117 - val_accuracy: 0.8700\n",
            "Epoch 174/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2175 - accuracy: 0.9790 - val_loss: 0.7987 - val_accuracy: 0.8731\n",
            "Epoch 175/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2181 - accuracy: 0.9797 - val_loss: 0.7854 - val_accuracy: 0.8742\n",
            "Epoch 176/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2149 - accuracy: 0.9800 - val_loss: 0.7966 - val_accuracy: 0.8734\n",
            "Epoch 177/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2165 - accuracy: 0.9792 - val_loss: 0.7994 - val_accuracy: 0.8746\n",
            "Epoch 178/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2190 - accuracy: 0.9786 - val_loss: 0.7963 - val_accuracy: 0.8758\n",
            "Epoch 179/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2154 - accuracy: 0.9803 - val_loss: 0.7960 - val_accuracy: 0.8729\n",
            "Epoch 180/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2134 - accuracy: 0.9804 - val_loss: 0.8180 - val_accuracy: 0.8694\n",
            "Epoch 181/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2115 - accuracy: 0.9815 - val_loss: 0.8160 - val_accuracy: 0.8723\n",
            "Epoch 182/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2150 - accuracy: 0.9791 - val_loss: 0.7802 - val_accuracy: 0.8729\n",
            "Epoch 183/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2083 - accuracy: 0.9823 - val_loss: 0.8026 - val_accuracy: 0.8718\n",
            "Epoch 184/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2078 - accuracy: 0.9817 - val_loss: 0.7978 - val_accuracy: 0.8708\n",
            "Epoch 185/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 0.2099 - accuracy: 0.9803 - val_loss: 0.8023 - val_accuracy: 0.8732\n",
            "Epoch 186/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2079 - accuracy: 0.9818 - val_loss: 0.8087 - val_accuracy: 0.8719\n",
            "Epoch 187/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2060 - accuracy: 0.9825 - val_loss: 0.7992 - val_accuracy: 0.8735\n",
            "Epoch 188/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2061 - accuracy: 0.9822 - val_loss: 0.8114 - val_accuracy: 0.8758\n",
            "Epoch 189/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2053 - accuracy: 0.9826 - val_loss: 0.8084 - val_accuracy: 0.8748\n",
            "Epoch 190/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.1994 - accuracy: 0.9847 - val_loss: 0.8376 - val_accuracy: 0.8733\n",
            "Epoch 191/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2048 - accuracy: 0.9824 - val_loss: 0.8202 - val_accuracy: 0.8718\n",
            "Epoch 192/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2065 - accuracy: 0.9805 - val_loss: 0.8034 - val_accuracy: 0.8748\n",
            "Epoch 193/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2010 - accuracy: 0.9829 - val_loss: 0.8160 - val_accuracy: 0.8734\n",
            "Epoch 194/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.2033 - accuracy: 0.9822 - val_loss: 0.8144 - val_accuracy: 0.8742\n",
            "Epoch 195/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.1996 - accuracy: 0.9834 - val_loss: 0.8115 - val_accuracy: 0.8737\n",
            "Epoch 196/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 0.1977 - accuracy: 0.9835 - val_loss: 0.8080 - val_accuracy: 0.8752\n",
            "Epoch 197/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.1980 - accuracy: 0.9831 - val_loss: 0.8379 - val_accuracy: 0.8735\n",
            "Epoch 198/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.1970 - accuracy: 0.9834 - val_loss: 0.8259 - val_accuracy: 0.8738\n",
            "Epoch 199/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.1951 - accuracy: 0.9847 - val_loss: 0.8324 - val_accuracy: 0.8738\n",
            "Epoch 200/200\n",
            "new lr:1.00e-03\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.1979 - accuracy: 0.9836 - val_loss: 0.8445 - val_accuracy: 0.8740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUtgEgI1IuWc"
      },
      "source": [
        "def plot_history(history):\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('Loss value')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('acc value')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "z6UMs0O72T-i",
        "outputId": "e17bb2ed-ea82-4278-9d57-cc570a0b4a22"
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hSpsz9v2WBV",
        "outputId": "430e47e6-1759-46ab-fecf-7869f75a7407"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 4s 14ms/step - loss: 0.9332 - accuracy: 0.8662\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9332308769226074, 0.8661999702453613]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ0w-9CcogSI"
      },
      "source": [
        "model.save('best_model.h5')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYOvkeYvo3GC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}